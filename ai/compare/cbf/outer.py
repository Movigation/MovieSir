#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ì™¸ì¬ì  í‰ê°€: Precision@10, Recall@10, NDCG@10
User Profile (Mean Embedding) ë°©ì‹
"""

import os
import sys
import numpy as np
import pandas as pd
from datetime import datetime
from tqdm import tqdm
from dotenv import load_dotenv

# ê²½ê³  ë¬´ì‹œ
import warnings
warnings.filterwarnings('ignore')

# ============================================================
# ì„¤ì •
# ============================================================
from pathlib import Path

# ê²½ë¡œ ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)
SCRIPT_DIR = Path(__file__).parent  # ai/compare/cbf/
PROJECT_ROOT = SCRIPT_DIR.parent.parent  # ai/

RATINGS_PATH = PROJECT_ROOT / 'training' / 'original_data' / 'ratings_tmdb.csv'
EMBEDDINGS_DIR = SCRIPT_DIR / 'inner_results'  # inner.pyì˜ ì¶œë ¥ í´ë”
RESULTS_DIR = SCRIPT_DIR / 'outer_results'     # ì™¸ì¬ì  í‰ê°€ ê²°ê³¼ í´ë”

os.makedirs(RESULTS_DIR, exist_ok=True)

# íŒŒë¼ë¯¸í„°
K = 10  # Top-K
N_USERS = 100  # í‰ê°€í•  ì‚¬ìš©ì ìˆ˜ (ìƒ˜í”Œë§)
MIN_RATINGS_PER_USER = 10  # (í•„í„°ë§ í›„) ìµœì†Œ í‰ì  ìˆ˜
POSITIVE_THRESHOLD = 4.0   # ê¸ì • í‰ì  ê¸°ì¤€ (4ì  ì´ìƒ)

print("="*60)
print("ì™¸ì¬ì  í‰ê°€: User Profile ê¸°ë°˜")
print("="*60)
print(f"K: {K}")
print(f"ëŒ€ìƒ ì‚¬ìš©ì ìˆ˜: {N_USERS}")
print(f"ê¸ì • ê¸°ì¤€: {POSITIVE_THRESHOLD}ì  ì´ìƒ")
print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

# ============================================================
# 1. ì˜í™” ëª©ë¡ ë° ì„ë² ë”© ë¡œë“œ (ê¸°ì¤€ ë°ì´í„°)
# ============================================================
def load_ground_truth():
    print("\nStep 1: ê¸°ì¤€ ì˜í™” ëª©ë¡ ë° ì„ë² ë”© ë¡œë“œ")

    # 1-1. ì˜í™” ëª©ë¡ ë¡œë“œ (movies_list.csv)
    movies_path = EMBEDDINGS_DIR / 'movies_list.csv'
    if not movies_path.exists():
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {movies_path}")
        sys.exit(1)

    movies_df = pd.read_csv(str(movies_path))
    # IDë¥¼ intë¡œ ê°•ì œ ë³€í™˜ (ë§¤ì¹­ ì˜¤ë¥˜ ë°©ì§€)
    movies_df['tmdb_id'] = movies_df['tmdb_id'].fillna(0).astype(int)
    
    # ìœ íš¨í•œ TMDB ID ì§‘í•© (Ground Truth)
    valid_tmdb_ids = set(movies_df['tmdb_id'].unique())
    
    # TMDB ID -> ì„ë² ë”© ì¸ë±ìŠ¤ ë§¤í•‘ (ë§¤ìš° ì¤‘ìš”)
    tmdb_to_idx = {tid: i for i, tid in enumerate(movies_df['tmdb_id'])}
    
    print(f"âœ… ê¸°ì¤€ ì˜í™” ìˆ˜ (Movies List): {len(movies_df):,}")

    # 1-2. ì„ë² ë”© ë¡œë“œ
    emb_path = EMBEDDINGS_DIR / 'embeddings.npz'
    if not emb_path.exists():
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {emb_path}")
        sys.exit(1)

    data = np.load(str(emb_path))
    embeddings = {
        'TF-IDF': data['tfidf'],
        'Word2Vec': data['word2vec'], # í‚¤ ì´ë¦„ í™•ì¸ í•„ìš” (word2vec_scratch ë“±ì¼ ìˆ˜ ìˆìŒ)
        'SBERT': data['sbert']
    }
    
    # ì„ë² ë”© ê°œìˆ˜ ê²€ì¦
    for name, emb in embeddings.items():
        if len(emb) != len(movies_df):
            print(f"âš ï¸ ê²½ê³ : {name} ì„ë² ë”© ìˆ˜({len(emb)})ì™€ ì˜í™” ìˆ˜({len(movies_df)}) ë¶ˆì¼ì¹˜!")
    
    return movies_df, valid_tmdb_ids, tmdb_to_idx, embeddings

# ============================================================
# 2. í‰ì  ë°ì´í„° ë¡œë“œ ë° ì—„ê²© í•„í„°ë§
# ============================================================
def prepare_ratings(valid_tmdb_ids):
    print("\nStep 2: í‰ì  ë°ì´í„° ë¡œë“œ ë° í•„í„°ë§")

    if not RATINGS_PATH.exists():
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {RATINGS_PATH}")
        sys.exit(1)

    # ë¡œë“œ ì‹œ íƒ€ì… ì§€ì • (ë©”ëª¨ë¦¬ ì ˆì•½ ë° ì˜¤ë¥˜ ë°©ì§€)
    ratings = pd.read_csv(str(RATINGS_PATH), dtype={'userId': int, 'tmdbId': float, 'rating': float})
    
    # NaN ì œê±° ë° int ë³€í™˜
    ratings = ratings.dropna(subset=['tmdbId'])
    ratings['tmdbId'] = ratings['tmdbId'].astype(int)
    
    print(f"ì›ë³¸ í‰ì  ìˆ˜: {len(ratings):,}")
    print(f"ì›ë³¸ ì˜í™” ìˆ˜: {ratings['tmdbId'].nunique():,}")
    
    # ğŸŒŸ í•µì‹¬: ì„ë² ë”©ì´ ìˆëŠ” ì˜í™”(valid_tmdb_ids)ë§Œ ë‚¨ê¸°ê³  ë‹¤ ë²„ë¦¼
    ratings = ratings[ratings['tmdbId'].isin(valid_tmdb_ids)].copy()
    
    print(f"í•„í„°ë§ í›„ í‰ì  ìˆ˜: {len(ratings):,}")
    print(f"í•„í„°ë§ í›„ ì˜í™” ìˆ˜: {ratings['tmdbId'].nunique():,}")
    
    if len(ratings) == 0:
        print("âŒ í•„í„°ë§ ê²°ê³¼ ë‚¨ì€ í‰ì ì´ ì—†ìŠµë‹ˆë‹¤. ID ë§¤ì¹­ì„ í™•ì¸í•˜ì„¸ìš”.")
        sys.exit(1)

    # ì‚¬ìš©ì í•„í„°ë§ (ìµœì†Œ Nê°œ ì´ìƒ í‰ê°€í•œ ì‚¬ëŒë§Œ)
    user_counts = ratings.groupby('userId').size()
    active_users = user_counts[user_counts >= MIN_RATINGS_PER_USER].index
    ratings = ratings[ratings['userId'].isin(active_users)].copy()
    
    print(f"ìµœì¢… í™œì„± ì‚¬ìš©ì ìˆ˜: {len(active_users):,}")
    print(f"ìµœì¢… ë°ì´í„° í¬ê¸°: {len(ratings):,}")
    
    return ratings

# ============================================================
# 3. ë°ì´í„° ë¶„í•  (Train/Test)
# ============================================================
def split_train_test(ratings):
    print("\nStep 3: ì‹œê°„ìˆœ Train/Test ë¶„í•  (8:2)")
    
    # ì‚¬ìš©ìë³„ ì‹œê°„ìˆœ ì •ë ¬
    ratings = ratings.sort_values(['userId', 'timestamp'])
    
    train_list = []
    test_list = []
    
    # groupby ì†ë„ ìµœì í™”
    for _, group in tqdm(ratings.groupby('userId'), desc="Splitting"):
        test_size = int(len(group) * 0.2)
        if test_size < 1: test_size = 1 # ìµœì†Œ 1ê°œëŠ” í…ŒìŠ¤íŠ¸ë¡œ
        
        train_list.append(group.iloc[:-test_size])
        test_list.append(group.iloc[-test_size:])
        
    train = pd.concat(train_list)
    test = pd.concat(test_list)
    
    print(f"Train: {len(train):,}, Test: {len(test):,}")
    return train, test

# ============================================================
# 4. í‰ê°€ ë©”íŠ¸ë¦­ í•¨ìˆ˜
# ============================================================
def get_metrics(recommended_indices, true_indices, k=10):
    # Intersection
    recommended_set = set(recommended_indices)
    true_set = set(true_indices)
    intersection = recommended_set.intersection(true_set)
    
    # Precision
    precision = len(intersection) / k
    
    # Recall
    recall = len(intersection) / len(true_set) if len(true_set) > 0 else 0
    
    # NDCG
    dcg = 0.0
    idcg = 0.0
    
    # DCG calc
    for i, idx in enumerate(recommended_indices):
        if idx in true_set:
            dcg += 1.0 / np.log2(i + 2)
            
    # IDCG calc
    num_relevant = min(len(true_set), k)
    for i in range(num_relevant):
        idcg += 1.0 / np.log2(i + 2)
        
    ndcg = dcg / idcg if idcg > 0 else 0
    
    return precision, recall, ndcg

# ============================================================
# 5. ëª¨ë¸ í‰ê°€ (User Profile ë°©ì‹)
# ============================================================
def evaluate(embeddings, train, test, tmdb_to_idx, users):
    
    # ì •ê·œí™” (Cosine Similarityë¥¼ ìœ„í•´)
    # Normì´ 0ì¸ ê²½ìš° ë°©ì§€
    norms = np.linalg.norm(embeddings, axis=1, keepdims=True)
    norms[norms == 0] = 1e-10
    emb_norm = embeddings / norms
    
    metrics = {'precision': [], 'recall': [], 'ndcg': []}
    
    for user in tqdm(users, desc="Evaluating"):
        # 1. User Profile ìƒì„± (Trainì—ì„œ ì¢‹ê²Œ ë³¸ ì˜í™”ë“¤ì˜ í‰ê·  ë²¡í„°)
        user_train = train[(train['userId'] == user) & (train['rating'] >= POSITIVE_THRESHOLD)]
        if len(user_train) == 0: continue
            
        train_movie_ids = user_train['tmdbId'].values
        train_indices = [tmdb_to_idx[mid] for mid in train_movie_ids]
        
        # ì‚¬ìš©ìê°€ ë³¸ ì˜í™” ë²¡í„°ë“¤ì˜ í‰ê· 
        user_vector = np.mean(emb_norm[train_indices], axis=0)
        
        # 2. ì „ì²´ ì˜í™”ì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚° (Dot Product)
        # (1, D) @ (N, D).T -> (1, N)
        scores = np.dot(user_vector, emb_norm.T)
        
        # 3. ì´ë¯¸ ë³¸ ì˜í™”(Train) ì œì™¸ ë§ˆìŠ¤í‚¹
        scores[train_indices] = -np.inf
        
        # 4. Top-K ì¶”ì²œ
        top_k_indices = np.argsort(scores)[::-1][:K]
        
        # 5. ì •ë‹µ í™•ì¸ (Test Set)
        user_test = test[(test['userId'] == user) & (test['rating'] >= POSITIVE_THRESHOLD)]
        if len(user_test) == 0: continue
            
        test_movie_ids = user_test['tmdbId'].values
        true_indices = [tmdb_to_idx[mid] for mid in test_movie_ids if mid in tmdb_to_idx]
        
        if not true_indices: continue
            
        p, r, n = get_metrics(top_k_indices, true_indices, k=K)
        metrics['precision'].append(p)
        metrics['recall'].append(r)
        metrics['ndcg'].append(n)
        
    return {k: np.mean(v) for k, v in metrics.items()}

# ============================================================
# Main Loop
# ============================================================
def main():
    # 1. ë°ì´í„° ì¤€ë¹„
    movies_df, valid_ids, tmdb_to_idx, embeddings_dict = load_ground_truth()
    ratings = prepare_ratings(valid_ids)
    train, test = split_train_test(ratings)
    
    # 2. í‰ê°€ ëŒ€ìƒ ì‚¬ìš©ì ìƒ˜í”Œë§
    test_users = test['userId'].unique()
    if len(test_users) > N_USERS:
        np.random.seed(42)
        target_users = np.random.choice(test_users, N_USERS, replace=False)
    else:
        target_users = test_users
        
    print(f"\nìµœì¢… í‰ê°€ ëŒ€ìƒ ì‚¬ìš©ì ìˆ˜: {len(target_users)}")
    
    # 3. ëª¨ë¸ë³„ í‰ê°€ ì‹¤í–‰
    final_results = []
    
    for model_name, emb_matrix in embeddings_dict.items():
        print(f"\nEvaluating {model_name}...")
        res = evaluate(emb_matrix, train, test, tmdb_to_idx, target_users)
        res['model'] = model_name
        final_results.append(res)
        
        print(f"Result ({model_name}):")
        print(f"  Precision@{K}: {res['precision']:.4f}")
        print(f"  Recall@{K}:    {res['recall']:.4f}")
        print(f"  NDCG@{K}:      {res['ndcg']:.4f}")

    # 4. ê²°ê³¼ ì €ì¥
    result_df = pd.DataFrame(final_results)
    save_path = RESULTS_DIR / 'final_evaluation_metrics.csv'
    result_df.to_csv(str(save_path), index=False)
    print(f"\nâœ… ìµœì¢… ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {save_path}")
    print(result_df)

if __name__ == "__main__":
    main()